{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/unihong/MS-AI-School/blob/main/20230731_Pytorch_Segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import VOCSegmentation\n",
        "from torch.utils.data import Dataset\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "class customVOCSegmentation(VOCSegmentation) :\n",
        "    def __init__(self, root, mode=\"train\", download=True,transforms=None):\n",
        "        self.root = root\n",
        "        super().__init__(root=self.root, image_set=mode,\n",
        "                         download=self.check_if_path_exists(), transforms=transforms )\n",
        "        # VOCSegmentation.__init__()\n",
        "        # VOCSegmentation 클래스의 생성자를 호출하며, 변경이 필요한 인자에 대해 받아서 넘겨줌.\n",
        "        # 해당 생성자에서 Custom Dataset의 생성자에서 필요한 작동을 모두 정의하고 있음\n",
        "        # (한 줄로 끝내서 간편함)\n",
        "        # 즉, 데이터셋 자체와 라벨 이미지 모두가 이 단락에서 생성이 완료됨\n",
        "\n",
        "        # self.check_if_path_exists() 편의 함수는 download 됐는지에 대한 여부 판별\n",
        "        #\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx) :\n",
        "        img = cv2.imread(self.images[idx])\n",
        "        mask = cv2.imread(self.masks[idx])\n",
        "\n",
        "        # 부모 클래서에서 원본 이미지는 self.images라는 이름으로 호출하도록 정의되어 있음\n",
        "        # 라벨에 해당하는 마스크는 self.masks라는 이름으로 호출하도록 정의되어 있음\n",
        "        # 해당 리스트는 이미지 자체가 아닌 해당 이미지 파일 경로만을 담고 있기 때문에, imread로 읽어줘야 함\n",
        "        if self.transforms: # == if self.transrform is not None :\n",
        "            augmented = self.transforms(image=img, mask=mask)\n",
        "            # cv2fmf chleogks 사용하는 것으로 가정하였으므로, torchvision의 transform 이 아닌\n",
        "            # albumentations 모듈을 사용하는 형태로 작성\n",
        "\n",
        "            # 또한, segmentation 의 경우 label 역할을 하는 mask 역시 이미지이며,\n",
        "            # image와 한 쌍을 이루기 때문에 transform 과정에서 함께 동일한 augmentation이 진행되어야 함.\n",
        "            img = augmented['image']\n",
        "            mask = augmented['mask']\n",
        "\n",
        "\n",
        "        return img, mask\n",
        "\n",
        "    def check_if_path_exists(self) :\n",
        "        #return False if os.path.exists(self.root) else True\n",
        "        return not os.path.exists(self.root)\n",
        "        # self.root 에 해당하는 data 폴더는 원래는 만들어지지 않았다가\n",
        "        # 클래스 선언과 함께 다운로드 받으며 만들어질 것\n",
        "        # 따라서, 해당 폴더가 존재한다면 다운로드 받을 필요가 없음 (False 반환)\n",
        "        # 반대로, 해당 폴더가 없다면 다운로드 받아야 함.(True 반환)\n",
        "\n",
        "    # __len__ 의 경우, 부모 클래스에서 자신의 구조를 정의하면서 함께 정의를 한 상태이기 때문에\n",
        "    # 주가로 재정의할 필요없음\n",
        "\n",
        "if __name__ == \"__main__\" :\n",
        "    # VOCSegmentation()\n",
        "    dataset = customVOCSegmentation(\"./data\")\n",
        "    for item in dataset:\n",
        "        img, mask = item\n",
        "        summary = cv2.copyTo(img, mask)\n",
        "        # copyTo 함수는 mask의 0이 아닌 부분에 img를 복사하도록 함 -> 라벨링 된 영역만 이미지가 표시됨\n",
        "        marked = cv2.addWeighted(img, 0.5, mask, 0.5, 0)\n",
        "        # addWeight 함수는 두 이미지에 대해서 입력한 가중치만금 더함. 원본이미지에 mask가 겹쳐 나옴.\n",
        "        # cv2.imshow(\"org\", img)\n",
        "        # cv2.imshow(\"mask\", mask)\n",
        "        #cv2.imshow(\"summary\", summary)\n",
        "        cv2.imshow(\"marked\", marked)\n",
        "        cv2.waitKey()\n",
        "        key = cv2.waitKey()\n",
        "        cv2.destroyAllWindows()\n",
        "        if key == ord('q') :\n",
        "            break"
      ],
      "metadata": {
        "id": "MPwhUu1UtW2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from torchvision.models.segmentation import deeplabv3_resnet101\n",
        "from torch.optim import Adam\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.utils.data import DataLoader\n",
        "from argparse import ArgumentParser\n",
        "from torchvision.datasets import VOCSegmentation\n",
        "\n",
        "class SegLearner:\n",
        "    def __init__(self, model, optimizer, criterion, train_dataloader, valid_dataloader):\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model = model.to(self.device)\n",
        "        self.criterion = criterion.to(self.device)\n",
        "        self.optimizer = optimizer\n",
        "        # 모델, 손실함수, 옵티마이저\n",
        "\n",
        "        self.train_dataloader = train_dataloader\n",
        "        self.valid_dataloader = valid_dataloader\n",
        "        # 데이터로더\n",
        "\n",
        "        #self.args = args\n",
        "        # 터미널 인자로 받은 필요값들\n",
        "\n",
        "        self.start_epoch = 0\n",
        "        self.metrics = {\n",
        "            \"train_loss\": [],\n",
        "            \"train_acc\": [],\n",
        "            \"train_miou\": [],\n",
        "            \"val_loss\": [],\n",
        "            \"val_acc\": [],\n",
        "            \"val_miou\": []\n",
        "        }\n",
        "        # resume이 걸릴 경우 / 학습이 저장될 경우 필요한 값들\n",
        "\n",
        "    def train(self):\n",
        "        for epoch in range(self.start_epoch, 10):\n",
        "            self.model.train()\n",
        "            train_loss = 0.0\n",
        "            train_corr = 0.0\n",
        "            val_loss = 0.0\n",
        "            val_corr = 0.0\n",
        "\n",
        "            train_iou = 0.0\n",
        "            val_iou = 0.0\n",
        "            # mIoU 계산을 위한 IoU 총합치 저장 변수\n",
        "\n",
        "            for i, (inputs, labels) in enumerate(tqdm(self.train_dataloader)):\n",
        "                inputs = inputs.float().to(self.device)\n",
        "                labels = labels.long().to(self.device)\n",
        "\n",
        "                self.optimizer.zero_grad() # 가중치 업데이트를 위한 optimizer 초기화\n",
        "\n",
        "                outputs = self.model(inputs) # 순전파\n",
        "                outputs = outputs[\"out\"] # deeplab은 output이 dict 형태로 쓸 수 있도록 나오므로, 출력치 key로 받아옴\n",
        "\n",
        "                loss = self.criterion(outputs, labels)\n",
        "                loss.backward() # 역전파\n",
        "                self.optimizer.step() # 가중치 업데이트\n",
        "\n",
        "                preds = torch.argmax(outputs, dim=1) # output으로부터 class에 대한 예측값을 얻음\n",
        "\n",
        "                train_loss += loss.item()\n",
        "                corrects = torch.sum(preds == labels.data) # labels와 preds는 이미지 형태\n",
        "                # 즉, 위의 line은 label 이미지와 preds 이미지를 겹쳤을 때, 일치하는 픽셀의 갯수가 나옴\n",
        "\n",
        "                # 이미지 형태이므로, 여기에서 나오는 총 길이는 최대 520x520 크기일것 (pretrained 기준)\n",
        "                batch_size = inputs.size(0)\n",
        "                train_corr += corrects.double() / (batch_size * 520 * 520)\n",
        "                # Pixel accuracy를 이용한 정확도 계산\n",
        "\n",
        "                train_iou += self.calc_iou(preds, labels.long())\n",
        "\n",
        "            _t_loss = train_loss / len(self.train_dataloader)\n",
        "            # 이번 epoch의 평균 train loss\n",
        "            _t_acc = train_corr / len(self.train_dataloader.dataset)\n",
        "            # 이번 epoch의 평균 pixel accuracy\n",
        "            _t_iou = train_iou / len(self.train_dataloader.dataset)\n",
        "            # 이번 epoch의 miou\n",
        "\n",
        "            self.metrics[\"train_loss\"].append(_t_loss)\n",
        "            self.metrics[\"train_acc\"].append(_t_acc)\n",
        "            self.metrics[\"train_miou\"].append(_t_iou)\n",
        "\n",
        "            print(f\"[{epoch + 1} / 10 ] train loss : {_t_loss}\",\n",
        "                  f\"train acc : {_t_acc}, train mIoU : {_t_iou}\")\n",
        "\n",
        "            # validation 시작\n",
        "            self.model.eval()\n",
        "            with torch.no_grad():\n",
        "                for val_i, (inputs, labels) in enumerate(tqdm(self.valid_dataloader)):\n",
        "                    inputs = inputs.to(self.device)\n",
        "                    labels = labels.long().to(self.device)\n",
        "\n",
        "                    outputs = self.model(inputs)\n",
        "                    outputs = outputs[\"out\"]\n",
        "                    loss = self.criterion(outputs, labels)\n",
        "                    preds = torch.argmax(outputs, dim=1)\n",
        "\n",
        "                    val_loss += loss.item()\n",
        "                    corrects = torch.sum(preds == labels.data)\n",
        "\n",
        "                    batch_size = inputs.size(0)\n",
        "                    val_corr += corrects.double() / (batch_size * 520 * 520)\n",
        "                    # Pixel accuracy를 이용한 정확도 계산\n",
        "                    val_iou += self.calc_iou(preds, labels.data)\n",
        "\n",
        "            _v_loss = val_loss / len(self.valid_dataloader)\n",
        "            _v_acc = val_corr / len(self.valid_dataloader.dataset)\n",
        "            _v_miou = val_iou / len(self.valid_dataloader.dataset)\n",
        "\n",
        "            self.metrics[\"val_loss\"].append(_v_loss)\n",
        "            self.metrics[\"val_acc\"].append(_v_acc)\n",
        "            self.metrics[\"val_miou\"].append(_v_miou)\n",
        "\n",
        "            print(f\"[{epoch + 1} / 10 ] valid loss : {_v_loss}\",\n",
        "                  f\"valid acc : {_v_acc}, valid mIoU : {_v_miou}\")\n",
        "\n",
        "            self.save_ckpts(epoch)\n",
        "\n",
        "\n",
        "    def load_ckpts(self):\n",
        "        '''\n",
        "        path: .pt 파일이 저장된 위치\n",
        "        '''\n",
        "        ckpt_path = os.path.join(\"./weight\", \"weight.pt\")\n",
        "        # 터미널 인자 args로부터 지정된 weight 로딩 경로를 받아옴\n",
        "\n",
        "        ckpt = torch.load(ckpt_path) # .pt 파일을 불러와서 dictionary 형태로 선언\n",
        "        self.model.load_state_dict(ckpt[\"model\"]) # dict 안에 있는 \"model\"키로 저장할 모델 가중치 로드\n",
        "        self.optimizer.load_state_dict(ckpt[\"optimizer\"])\n",
        "        self.start_epoch = ckpt[\"epoch\"]\n",
        "        self.metrics = ckpt[\"metrics\"]\n",
        "\n",
        "    def save_ckpts(self, epoch, file_name=None):\n",
        "        # 체크포인트 저장을 처리하기 위한 편의함수\n",
        "        if not os.path.exists(\"./weight\"):\n",
        "            os.makedirs(\"./weight\", exist_ok=True)\n",
        "        # 모델 가중치가 저장될 폴더가 없을 경우, 오류가 날 수 있으므로\n",
        "        # 터미널 인자 args에서 받은 model_folder_path가 있는지 확인 후, 없으면 생성\n",
        "\n",
        "        if file_name is None:\n",
        "            to_save_path = os.path.join(\"./weight\", \"weight.pt\")\n",
        "        else:\n",
        "            to_save_path = os.path.join(\"./weight\", file_name)\n",
        "        # file name 커스텀을 위한 조건식 부분\n",
        "\n",
        "        torch.save(\n",
        "            {\n",
        "                \"model\": self.model.state_dict(), # 현재 가중치 값\n",
        "                \"optimizer\": self.optimizer.state_dict(), # optimizer의 현재 수치\n",
        "                \"epoch\": epoch,\n",
        "                \"metrics\": self.metrics\n",
        "            }, to_save_path\n",
        "        )\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def calc_iou(preds, labels):\n",
        "        total_iou = 0.0\n",
        "        # 들어온 batch의 IoU 총합\n",
        "        for inp, ans in zip(preds, labels):\n",
        "            # inp == preds에서 들어온, 예측치가 담겨있는 단일 이미지(텐서)\n",
        "            # ans == labels에서 들어온, 정답치가 담겨있는 단일 이미지(텐서)\n",
        "            inp = inp.cpu().numpy()\n",
        "            # inp는 device에 넘어가있는 텐서이므로, cpu로 넘겨준 뒤 텐서에서 numpy 행렬로 변환\n",
        "            ans = ans.cpu().numpy()\n",
        "\n",
        "            union_section = np.logical_or(inp, ans)\n",
        "            inter_section = np.logical_and(inp, ans)\n",
        "            # 위에서 or, and 연산을 통해 얻은 numpy 행렬은 Boolean 행렬이며, 계산에 사용할 수 있는 수가 아님\n",
        "\n",
        "            # cv2.imshow(\"union\", union_section.astype(np.uint8) * 255)\n",
        "            # 마스크 확인용 imshow 코드\n",
        "\n",
        "            uni_sum = np.sum(union_section)\n",
        "            inter_sum = np.sum(inter_section)\n",
        "            # 해당하는 행렬의 총 픽셀 수 (T/F Boolean mask 형태로 나올 것이므로 sum을 하면 픽셀 수를 얻음)\n",
        "            # == 해당 영역의 넓이\n",
        "            if uni_sum != 0:\n",
        "                total_iou += inter_sum / uni_sum\n",
        "            else:\n",
        "                total_iou += 0\n",
        "            # 성공적인 데이터 입력의 경우 uni_sum이 0이 될 일은 없음 (정답지 mask가 완전히 검은 이미지는 없으므로)\n",
        "            # 그러나 만약의 경우를 대비하여 0으로 나눈 오류가 나지 않도록 처리\n",
        "\n",
        "            # 교집합 넓이 / 합집합 넓이 = IoU\n",
        "\n",
        "        return total_iou\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    mean = [0.485, 0.456, 0.406]\n",
        "    std = [0.229, 0.224, 0.225]\n",
        "    # 실험에 의해 도출된, 가장 좋은 결과를 도출하는 평균/표준편차 값들\n",
        "\n",
        "    train_transforms = A.Compose([\n",
        "        A.Resize(520, 520), # DeepLabV3 pretrain 모델이 사용할 이미지 크기 (520x520)\n",
        "\n",
        "        A.HorizontalFlip(p=0.5), # 50% 확률로 좌우반전\n",
        "\n",
        "        A.Normalize(mean=mean, std=std),\n",
        "        ToTensorV2() # torch 모델에 넣을 수 있도록 ToTensor 사용\n",
        "    ])\n",
        "\n",
        "    valid_transforms = A.Compose([\n",
        "        A.Resize(520, 520), # DeepLabV3 pretrain 모델이 사용할 이미지 크기 (520x520)\n",
        "        A.Normalize(mean=mean, std=std),\n",
        "        ToTensorV2()\n",
        "    ])\n",
        "\n",
        "    # # 아래에 dataset과 dataloader 등등에 필요한 터미널 인자를 지정하기 위해 argparser 사용\n",
        "    # parser = ArgumentParser()\n",
        "    # parser.add_argument(\"--data_path\", type=str, default=\"./data\",\n",
        "    #                     help=\"데이터셋 파일이 저장되거나 로딩될 지점\")\n",
        "    # parser.add_argument(\"--weight_folder_path\", type=str, default=\"./weight\",\n",
        "    #                     help=\"가중치가 저장될 폴더의 경로\")\n",
        "    # parser.add_argument(\"--weight_file_name\", type=str, default=\"weight.pt\",\n",
        "    #                     help=\"저장될 가중치 파일의 이름\")\n",
        "    # parser.add_argument(\"--batch_size\", type=int, default=2,\n",
        "    #                     help=\"Batch size\")\n",
        "    # parser.add_argument(\"--num_workers\", type=int, default=4,\n",
        "    #                     help=\"데이터로더가 사용할 프로세스 수, 사용자 컴퓨터 환경에 따라 달라질 수 있음\")\n",
        "    # parser.add_argument(\"--learning_rate\", type=float, default=0.001,\n",
        "    #                     help=\"learning rate\")\n",
        "    # parser.add_argument(\"--weight_decay\", type=float, default=0.01,\n",
        "    #                     help=\"lr의 감소율\")\n",
        "    # parser.add_argument(\"--resume\", action=\"store_true\",\n",
        "    #                     help=\"학습 재개 여부, store_true가 지정되면 터미널 인자로 선언되어야 true가 들어옴\")\n",
        "    # parser.add_argument(\"--epochs\", type=int, default=10,\n",
        "    #                     help=\"이번 학습의 총 epoch 수\")\n",
        "    # args = parser.parse_args()\n",
        "\n",
        "    train_dataset = customVOCSegmentation(\"./data\", mode=\"train\", transforms=train_transforms)\n",
        "    valid_dataset = customVOCSegmentation(\"./data\", mode=\"val\", transforms=valid_transforms)\n",
        "    # dataset 선언\n",
        "\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=2, num_workers=4,\n",
        "                                  shuffle=True, drop_last=True)\n",
        "    valid_dataloader = DataLoader(valid_dataset, batch_size=2, num_workers=4)\n",
        "    # dataloader 선언\n",
        "\n",
        "    model = deeplabv3_resnet101(pretrained=True)\n",
        "    # model 선언 (pretrained 모델 사용)\n",
        "\n",
        "    optimizer = Adam(model.parameters(), lr=0.001, weight_decay=0.01)\n",
        "    criterion = CrossEntropyLoss(ignore_index=255)\n",
        "\n",
        "    # train을 위해 만든 편의 class 선언\n",
        "    learner = SegLearner(model, optimizer, criterion, train_dataloader, valid_dataloader)\n",
        "\n",
        "    # if args.resume:\n",
        "    #     learner.load_ckpts()\n",
        "\n",
        "    # 학습 시작\n",
        "    learner.train()\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jk8rnjVJMEvJ",
        "outputId": "db14b74f-4800-4624-cb92-50e1d9b76812"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 732/732 [04:10<00:00,  2.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 / 10 ] train loss : 1.2704386176551625 train acc : 0.37406201372384973, train mIoU : 0.0032783750210137624\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 725/725 [01:26<00:00,  8.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 / 10 ] valid loss : 1.2770283775288482 valid acc : 0.3695806942964129, valid mIoU : 0.024406891690545315\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 732/732 [04:07<00:00,  2.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2 / 10 ] train loss : 1.2049932537264512 train acc : 0.37449024239539846, train mIoU : 0.00043991962797723086\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 725/725 [01:26<00:00,  8.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2 / 10 ] valid loss : 1.2093540296472352 valid acc : 0.3739876485925817, valid mIoU : 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 732/732 [04:07<00:00,  2.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3 / 10 ] train loss : 1.1957608220355758 train acc : 0.3745176645811102, train mIoU : 3.4015787299162283e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 725/725 [01:26<00:00,  8.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3 / 10 ] valid loss : 1.2064142545749401 valid acc : 0.3739876485925817, valid mIoU : 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 732/732 [04:07<00:00,  2.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4 / 10 ] train loss : 1.1906940036051261 train acc : 0.37451766458110997, train mIoU : 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 725/725 [01:26<00:00,  8.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4 / 10 ] valid loss : 1.1955270428493106 valid acc : 0.3739876485925817, valid mIoU : 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 732/732 [04:07<00:00,  2.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5 / 10 ] train loss : 1.1876011276261402 train acc : 0.3745176645811103, train mIoU : 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 725/725 [01:26<00:00,  8.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5 / 10 ] valid loss : 1.2038660091983862 valid acc : 0.3739876485925817, valid mIoU : 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 732/732 [04:07<00:00,  2.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[6 / 10 ] train loss : 1.1875358798790498 train acc : 0.37451766458111013, train mIoU : 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 725/725 [01:26<00:00,  8.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[6 / 10 ] valid loss : 1.197692817655103 valid acc : 0.3739876485925817, valid mIoU : 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 732/732 [04:07<00:00,  2.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7 / 10 ] train loss : 1.1853454360952143 train acc : 0.3745176645811103, train mIoU : 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 725/725 [01:26<00:00,  8.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7 / 10 ] valid loss : 1.1818361101890433 valid acc : 0.3739876485925817, valid mIoU : 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 732/732 [04:06<00:00,  2.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[8 / 10 ] train loss : 1.1840372892921087 train acc : 0.3745176645811102, train mIoU : 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 725/725 [01:26<00:00,  8.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[8 / 10 ] valid loss : 1.192383989034028 valid acc : 0.3739876485925817, valid mIoU : 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 732/732 [04:07<00:00,  2.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[9 / 10 ] train loss : 1.1866404663751033 train acc : 0.37451766458111035, train mIoU : 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 725/725 [01:26<00:00,  8.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[9 / 10 ] valid loss : 1.2137249261962957 valid acc : 0.3739876485925817, valid mIoU : 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 732/732 [04:07<00:00,  2.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10 / 10 ] train loss : 1.1839683448763494 train acc : 0.3745176645811105, train mIoU : 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 725/725 [01:26<00:00,  8.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10 / 10 ] valid loss : 1.170155117059576 valid acc : 0.3739876485925817, valid mIoU : 0.0\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyOwGim7/a0dvH/BetqFr22f",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}